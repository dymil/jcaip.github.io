---
layout: page
permalink: /about/
---

Hi there!

I'm Jesse Cai, and this is my blog about random stuff that interests me. 

If you want to get a feel for what I write about I'd recommend reading the following posts:

- Experimental and theoretical analysis of [sentence representations](/Quickthoughts)
- [Distributed gradient descent](/Distbelief) in PyTorch
- Constructing the [rational numbers](/Building-Q) visually
- Using RNNs to [predict user activity](/Predicting-User-Submission)


## About Me

I do research as part of [UCLA-NLP](http://web.cs.ucla.edu/~kwchang/) here at UCLA.

I'm interested in representation and transfer learning in NLP, new approaches to inference on sentence/word vectors, and automating tedious tasks with machine learning. 

My main research interest has been how to leverage unlabeled but structured data to learn better sentence embeddings.

<img src="/images/ex.png" alt="example" width="300" class="center"/>

In layman's terms, I tried to find a way to take a sentence and change it into a bunch of numbers ( a vector in $\mathbb{R}^n$), but in a way so that if you plotted sentences with similar meanings, they would be close to each other. 

Machine learning is fundamentally a combination of **representation** and **optimization**, so having representations that make our optimization problems easier is important. 

I have a mix of industry and academia experience. 

I took some time off school in 2017-18 to join the data team at [Blend](https://blend.com), where I used deep learning to identify app quality issues from NPS comments. Before that I used to intern at [JPL](https://www.jpl.nasa.gov/).

In my free time I like lifting, exploring nature, and eating tasty things.

If you want to chat about anything feel free to reach out or email me. 
