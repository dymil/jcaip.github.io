---
layout: page
permalink: /about/
---

Hi there!

I'm Jesse Cai, and this is my blog about stuff that interests me - mostly ml/nlp/startups.

I'm a machine learning engineer at [Cultivate](https://trycultivate.com/).

I graduated from UCLA, where I used to do NLP research on representation learning with Professor Kai-Wei Chang.

In my free time I like to lift, hike and eat ramen. 

If your new here I'd recommend reading the following posts:

- Combining sentence embeddings and clique percolation to [find topics in text](/Kernels-and-Cliques)
- Experimental and theoretical analysis of [sentence representations](/Quickthoughts)
- [Distributed gradient descent](/Distbelief) in PyTorch
- Constructing the [rational numbers](/Building-Q) visually
- Using RNNs to [predict user activity](/Predicting-User-Submission)

<!--Or alternatively, these are some questions I would like to know the answers to / things I would like to learn more about:-->

<!--- Is it ever rational to be irrational? Suppose you're playing a game with -->
<!--- Is relational knowledge distillation viable? See [here]. Basically instead of doing distillation as a KL between $P(y \mid x, \theta)$ and . When I was still doing research I tried to use this to distill BERT, but it didn't work so well. So really interested in any new work / thoughts on this approach. -->
<!--- What makes a manager *good*? Happy to hear generals or specifics here. -->
<!--- I've always felt self-studying mathematics = trying to hammer a nail with my head, but lectures were quite interesting. However, when learning computer science, I felt the opposite - lectures were boring but projects were more engaging. Are certain subjects just easier to learn? If so what makes a subject harder/easier?-->

